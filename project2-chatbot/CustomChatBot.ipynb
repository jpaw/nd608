{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124e5672",
   "metadata": {},
   "source": [
    "# Custom Chatbot Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a94b3",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Project Overview and Rationale](#rationale)\n",
    "2. [Dataset Preparation](#preparation)\n",
    "3. [Custom Query Process](#custom_queries)\n",
    "4. [Demo Questions](#demo)\n",
    "\n",
    "## Project Overview and Rationale\n",
    "<a id=\"rationale\"></a>\n",
    "This project will use the provided data \"Fashion Trends\" to improve the answers of ChatGPT about fashion.\n",
    "\n",
    "The fictional scenario is as follows: The year is 2023, and we are operating an e-commerce web shop specializing in fashion. We want to offer our customers a text based assistant which helps them choosing their next outfit.\n",
    "\n",
    "The reasons to use the fashion trends data set are as follows:\n",
    "- The data is real life data. This is a plus compared to other data generated by the AI once we want to compare the responses of ChatGPT with vs without custom data\n",
    "- The task fits well into my current actual job (building web shop and order management back ends) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63d4c5f",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "\n",
    "<a id=\"preparation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c69b83a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a595980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                                                   URL  \\\n",
      "0   https://www.refinery29.com/en-us/fashion-trend...   \n",
      "1   https://www.refinery29.com/en-us/fashion-trend...   \n",
      "2   https://www.refinery29.com/en-us/fashion-trend...   \n",
      "3   https://www.refinery29.com/en-us/fashion-trend...   \n",
      "4   https://www.refinery29.com/en-us/fashion-trend...   \n",
      "..                                                ...   \n",
      "77  https://www.whowhatwear.com/spring-summer-2023...   \n",
      "78  https://www.whowhatwear.com/spring-summer-2023...   \n",
      "79  https://www.whowhatwear.com/spring-summer-2023...   \n",
      "80  https://www.whowhatwear.com/spring-summer-2023...   \n",
      "81  https://www.whowhatwear.com/spring-summer-2023...   \n",
      "\n",
      "                                               Trends  \\\n",
      "0   2023 Fashion Trend: Red. Glossy red hues took ...   \n",
      "1   2023 Fashion Trend: Cargo Pants. Utilitarian w...   \n",
      "2   2023 Fashion Trend: Sheer Clothing. \"Bare it a...   \n",
      "3   2023 Fashion Trend: Denim Reimagined. From dou...   \n",
      "4   2023 Fashion Trend: Shine For The Daytime. The...   \n",
      "..                                                ...   \n",
      "77  If lime green isn't your vibe, rest assured th...   \n",
      "78  \"As someone who can clearly (not fondly) remem...   \n",
      "79  \"Combine this design shift with the fact that ...   \n",
      "80  Thought party season ended at the stroke of mi...   \n",
      "81  \"This season, we saw the revival of the bubble...   \n",
      "\n",
      "                                               Source  \n",
      "0   7 Fashion Trends That Will Take Over 2023 — Sh...  \n",
      "1   7 Fashion Trends That Will Take Over 2023 — Sh...  \n",
      "2   7 Fashion Trends That Will Take Over 2023 — Sh...  \n",
      "3   7 Fashion Trends That Will Take Over 2023 — Sh...  \n",
      "4   7 Fashion Trends That Will Take Over 2023 — Sh...  \n",
      "..                                                ...  \n",
      "77  Spring/Summer 2023 Fashion Trends: 21 Expert-A...  \n",
      "78  Spring/Summer 2023 Fashion Trends: 21 Expert-A...  \n",
      "79  Spring/Summer 2023 Fashion Trends: 21 Expert-A...  \n",
      "80  Spring/Summer 2023 Fashion Trends: 21 Expert-A...  \n",
      "81  Spring/Summer 2023 Fashion Trends: 21 Expert-A...  \n",
      "\n",
      "[82 rows x 3 columns]>\n"
     ]
    }
   ],
   "source": [
    "# read the data\n",
    "df_full = pd.read_csv(\"data/2023_fashion_trends.csv\")\n",
    "print(df_full.head)\n",
    "# => labels are URL, trends, source, size of set is 82 rows (without headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acb3a9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<bound method NDFrame.head of                                                  text\n",
      "0   2023 Fashion Trend: Red. Glossy red hues took ...\n",
      "1   2023 Fashion Trend: Cargo Pants. Utilitarian w...\n",
      "2   2023 Fashion Trend: Sheer Clothing. \"Bare it a...\n",
      "3   2023 Fashion Trend: Denim Reimagined. From dou...\n",
      "4   2023 Fashion Trend: Shine For The Daytime. The...\n",
      "..                                                ...\n",
      "77  If lime green isn't your vibe, rest assured th...\n",
      "78  \"As someone who can clearly (not fondly) remem...\n",
      "79  \"Combine this design shift with the fact that ...\n",
      "80  Thought party season ended at the stroke of mi...\n",
      "81  \"This season, we saw the revival of the bubble...\n",
      "\n",
      "[82 rows x 1 columns]>\n"
     ]
    }
   ],
   "source": [
    "# convert into single column set with label \"text\"\n",
    "df_text = pd.DataFrame(df_full[\"Trends\"]).rename(columns={'Trends': 'text'}) # source for rename: Udacity GPT chatbot\n",
    "\n",
    "print(type(df_text))\n",
    "print(df_text.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae769871",
   "metadata": {},
   "source": [
    "## Custom Query Completion\n",
    "\n",
    "<a id=\"custom_queries\"></a>\n",
    "[OpenAI API reference](https://platform.openai.com/docs/api-reference/chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "582f0656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key to access OpenAI\n",
    "OPENAI_API_KEY = \"YOUR_API_KEY\"\n",
    "\n",
    "# select some configuration settings\n",
    "DEFAULT_TEMPERATURE = 0.1\n",
    "\n",
    "# Pick one of the models available. Should use only combinations which have the same encoding (cl100k_base in this case)\n",
    "# THE_COMPLETION_MODEL = \"text-davinci-003\" # uses p50k_base (source: https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken)\n",
    "THE_COMPLETION_MODEL = \"gpt-3.5-turbo-instruct\"\n",
    "# THE_EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "THE_EMBEDDING_MODEL = \"text-embedding-3-small\"  # OpenAI doc says this embedding is cheaper and up to date\n",
    "THE_TOKEN_ENCODING = \"cl100k_base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b6e1f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings for this session. We don't have that much data to require iterations\n",
    "\n",
    "import openai\n",
    "\n",
    "# Send text data to OpenAI model to get embeddings\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "response_for_embeddings = openai.Embedding.create(\n",
    "    input  = df_text[\"text\"].to_list(),\n",
    "    engine = THE_EMBEDDING_MODEL\n",
    ")\n",
    "\n",
    "embeddings = response_for_embeddings[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13f2dcd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'openai.openai_object.OpenAIObject'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# save the embeddings to save cost if we need them again (in a real world application this should be a vector database)\n",
    "import numpy as np\n",
    "\n",
    "# we want the embeddings as 1) DataFrame (to save) and 2) as list of numpy arrays (for the OpenAI nearest neighbor search)\n",
    "# conversion mayhem..., I bet this is possible a lot easier\n",
    "print(type(embeddings))\n",
    "print(type(embeddings[0]))\n",
    "# print(embeddings[0])\n",
    "print(type(embeddings[0].get(\"embedding\")))\n",
    "\n",
    "# calculate embeddings as list of ndarray\n",
    "embeddings_np = [ np.array(e.get('embedding')) for e in embeddings ]\n",
    "\n",
    "# add it to the existing DataFrame and save that\n",
    "df_text[\"embeddings\"] = embeddings_np\n",
    "df_text.to_csv(\"embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97f25e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read (restart point)\n",
    "#df_embeddings = pd.read_csv(\"embeddings.csv\", index_col=0)\n",
    "#df_embeddings[\"embeddings\"] = df_embeddings[\"embeddings\"].apply(eval).apply(np.array)\n",
    "#df_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e4fe22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a search for the most relevant statements\n",
    "# (again, in a real world application, the would be a vector database query, have to try this later)\n",
    "# this implementation taken from prior course material\n",
    "\n",
    "from openai.embeddings_utils import get_embedding, distances_from_embeddings\n",
    "\n",
    "def get_rows_sorted_by_relevance(question, df):\n",
    "    \"\"\"\n",
    "    Function that takes in a question string and a dataframe containing\n",
    "    rows of text and associated embeddings, and returns that dataframe\n",
    "    sorted from least to most relevant for that question\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get embeddings for the question text\n",
    "    question_embeddings = get_embedding(question, engine=THE_EMBEDDING_MODEL)\n",
    "    \n",
    "    # Make a copy of the dataframe and add a \"distances\" column containing\n",
    "    # the cosine distances between each row's embeddings and the\n",
    "    # embeddings of the question\n",
    "    df_copy = df.copy()\n",
    "    df_copy[\"distances\"] = distances_from_embeddings(\n",
    "        question_embeddings,\n",
    "        embeddings_np,\n",
    "        distance_metric=\"cosine\"\n",
    "    )\n",
    "    \n",
    "    # Sort the copied dataframe by the distances and return it\n",
    "    # (shorter distance = more relevant so we sort in ascending order)\n",
    "    df_copy.sort_values(\"distances\", ascending=True, inplace=True)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c403f543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "# computes the embedding for a single string, returns a list\n",
    "# should match the openai.embeddings_utils function get_embedding\n",
    "def get_embedding_for_question(question):\n",
    "    response_for_embeddings = openai.Embedding.create(\n",
    "        input  = question,\n",
    "        engine = THE_EMBEDDING_MODEL\n",
    "    )\n",
    "    return response_for_embeddings.data[0][\"embedding\"]\n",
    "\n",
    "test_question = 'Which kind of jacket should I wear?'\n",
    "rs = get_embedding_for_question(test_question)\n",
    "print(type(rs))\n",
    "# print(rs)\n",
    "# rs2 = get_embedding(test_question, engine=THE_EMBEDDING_MODEL)\n",
    "# print(type(rs2))\n",
    "# print(rs2)\n",
    "\n",
    "\n",
    "# embeddings = response_for_embeddings[\"data\"]\n",
    "def create_prompt_with_context(question, df):\n",
    "    \"\"\"\n",
    "    Given a question and a dataframe containing rows of text and their\n",
    "    embeddings, return a text prompt to send to a Completion model\n",
    "    \"\"\"\n",
    "    # Create a tokenizer that is designed to align with our embeddings\n",
    "    tokenizer = tiktoken.get_encoding(THE_TOKEN_ENCODING)\n",
    "\n",
    "    # Count the number of tokens in the prompt template and question\n",
    "    prompt_template = \"\"\"\n",
    "You are a fashion advisor. It is the year 2023.\n",
    "Answer the question based on the context of the current year's trends below, and if the question\n",
    "can't be answered based on the context, say \"I don't know\"\n",
    "\n",
    "Context: \n",
    "\n",
    "{}\n",
    "\n",
    "---\n",
    "\n",
    "Question: {}\n",
    "Answer:\"\"\"\n",
    "    current_token_count = len(tokenizer.encode(prompt_template)) + len(tokenizer.encode(question))\n",
    "    max_token_count = 1024\n",
    "    max_relevant_facts = 8\n",
    "\n",
    "    context = []\n",
    "    # add facts to the context as long as we don't exceed the token count and we don't add more than max_relevant_facts\n",
    "    for text in get_rows_sorted_by_relevance(question, df)[\"text\"].values:\n",
    "\n",
    "        # Increase the counter based on the number of tokens in this row\n",
    "        text_token_count = len(tokenizer.encode(text))\n",
    "        current_token_count += text_token_count\n",
    "\n",
    "        # Add the row of text to the list if we haven't exceeded the max\n",
    "        if current_token_count <= max_token_count and len(context) < max_relevant_facts:\n",
    "            context.append(text)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    print(f'Used {len(context)} trend information records')\n",
    "    return prompt_template.format(\"\\n\\n###\\n\\n\".join(context), question)\n",
    "\n",
    "def create_standard_prompt(question, df):\n",
    "    prompt_template = \"\"\"\n",
    "You are a fashion advisor. Answer the following question:\n",
    "Question: {}\n",
    "Answer:\"\"\"\n",
    "    return prompt_template.format(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "74280b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a method to answer a customer's question.\n",
    "# The caller must provide the customer's question, and can optionally also set a temperature, because for fashion there is\n",
    "# usually no right or wrong, because a lot depends on personal preference. Therefore a bit of variety is good. It also\n",
    "# allows the customer to repeat the question and get a different opionion.\n",
    "#\n",
    "# The method uses the following globally defined data:\n",
    "# - DEFAULT_TEMPERATURE: a value for the creativity of the bot\n",
    "# - embeddings: the embeddings which hold the additional knowledge past 2021\n",
    "\n",
    "def chat_completion(prompt, temperature=DEFAULT_TEMPERATURE):\n",
    "    # print(computed_prompt)\n",
    "    response = openai.Completion.create(\n",
    "        model       = THE_COMPLETION_MODEL,\n",
    "        prompt      = prompt,\n",
    "        temperature = temperature,\n",
    "        max_tokens  = 256,\n",
    "        top_p       = 1.0 if temperature == 0.0 else 0.9\n",
    "    )\n",
    "    return response.choices[0].text.strip().strip(\"\\n\")\n",
    "\n",
    "def compare_results(question):\n",
    "    print(f'Question: {question}')\n",
    "    print(f'Answer of base model: {chat_completion(create_standard_prompt(question, df_text), 0.0)}')\n",
    "    print(f'Answer of custom model: {chat_completion(create_prompt_with_context(question, df_text), 0.0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1783f146",
   "metadata": {},
   "source": [
    "## Custom Performance Demonstration\n",
    "\n",
    "<a id=\"demo\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f11fdc0",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4901c850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What kind of bag should I use?\n",
      "Answer of base model: It depends on the occasion and your personal style. For a casual day out, a crossbody or tote bag would be a practical and stylish choice. For a more formal event, a clutch or structured handbag would be more appropriate. If you prefer a more edgy look, a backpack or fanny pack could be a fun option. Ultimately, choose a bag that complements your outfit and makes you feel confident.\n",
      "Used 8 trend information records\n",
      "Answer of custom model: Oversized bags are currently trending in 2023, so a big tote or shoulder bag would be a great choice.\n"
     ]
    }
   ],
   "source": [
    "compare_results('What kind of bag should I use?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e857bb1",
   "metadata": {},
   "source": [
    "Result: Both models give a meaningful result, but clearly the one without the custom facts is quite generic, while the one with the extra information is very specific and takes the context into account."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e86e37c",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6f646989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: I need some more shoes, can you recommend some slippers?\n",
      "Answer of base model: Sure, there are many great slipper options available. For a casual and comfortable option, I would recommend a pair of fuzzy or plush slippers. If you're looking for something more stylish, you could try a pair of mules or slides with a fun print or embellishment. For a more formal option, you could go for a pair of velvet or satin slippers. Ultimately, it depends on your personal style and the occasion you will be wearing them for.\n",
      "Used 7 trend information records\n",
      "Answer of custom model: For a comfortable yet stylish option, I would recommend the Khaite Marcy shearling flat. For a more glamorous option, the Alaïa Coeur mule would be a great choice. And for a fun and youthful option, the platform slip-ons mentioned by personal stylist Andie Sobrato would be a great addition to your shoe collection.\n"
     ]
    }
   ],
   "source": [
    "compare_results('I need some more shoes, can you recommend some slippers?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acabf0df",
   "metadata": {},
   "source": [
    "Result: Similar to question 1, the custom bot follows the 2023 fashion trends much closer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd7fe80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
