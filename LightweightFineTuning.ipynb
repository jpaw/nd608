{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "TODO: In this cell, describe your choices for each of the following\n",
    "\n",
    "* PEFT technique: As recommended, I will use LoRA \n",
    "* Model: I learned that gpt is better for CausalLM, therefore I will use bert instead of gpt-2\n",
    "* Evaluation approach: TODO\n",
    "* Fine-tuning dataset: Despite being similar to imdb, I will use movie reviews, but here from rotten tomatos. Main reason is it is the first data set I find which has an appropriate size (5331 records per sentiment, with a 50/50 distribution)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f551c63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers as tf  # probably a bad idea, tf could be mistaken for tensorflow, will pick another abbrev next time\n",
    "import datasets as ds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import evaluate as eva\n",
    "import torch.nn.functional as func\n",
    "import peft\n",
    "\n",
    "# config: pick one of the next 3\n",
    "# THE_MODEL_I_USE = \"gpt2\"                  # suggested, but not that suitable for classification\n",
    "THE_MODEL_I_USE = \"distilbert-base-uncased\" # current selection\n",
    "# THE_MODEL_I_USE = \"bert-base-cased\"       # big\n",
    "\n",
    "# Config: train the classiication head? If not, the initial evaluation is more or less random, if done, these weights won't be saved and are lost\n",
    "TRAIN_CH = True\n",
    "\n",
    "# the name of the tuned model is the original one plus some suffix\n",
    "NAME_OF_FINETUNED_MODEL = THE_MODEL_I_USE + \"-loratuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4935cb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count t/v/t is 8530/1066/1066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 1066\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data set\n",
    "allsets = ds.load_dataset(\"rotten_tomatoes\")\n",
    "\n",
    "# split into its parts\n",
    "part_train      = allsets[\"train\"]\n",
    "part_validation = allsets[\"validation\"]\n",
    "part_test       = allsets[\"test\"]\n",
    "\n",
    "# print sizes\n",
    "print(f\"Count t/v/t is {len(part_train)}/{len(part_validation)}/{len(part_test)}\")\n",
    "# => awesome, some decent size!\n",
    "\n",
    "# inspect it:\n",
    "part_test\n",
    "# => has text and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f28c4a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertForSequenceClassification(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n",
      "I obtained Bleh! for This was a really bad movie\n"
     ]
    }
   ],
   "source": [
    "def to_label(token):\n",
    "    return \"Bleh!\" if token == 0 else \"Yeah!\"\n",
    "\n",
    "original_tokenizer = tf.AutoTokenizer.from_pretrained(THE_MODEL_I_USE) # , return_tensors=\"pt\")\n",
    "original_model = tf.AutoModelForSequenceClassification.from_pretrained(THE_MODEL_I_USE, num_labels=2,\n",
    "    id2label={0: \"Bleh!\", 1: \"Yeah!\"},\n",
    "    label2id={\"Bleh!\": 0, \"Yeah!\": 1}\n",
    ")\n",
    "\n",
    "# set padding (quite an effort to make it work!)\n",
    "original_tokenizer.pad_token = original_tokenizer.eos_token\n",
    "original_model.config.pad_token_id = original_model.config.eos_token_id\n",
    "original_tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "print(original_model)\n",
    "\n",
    "# test the tokenizer on some fixed text\n",
    "sample_text = \"This was a really bad movie\"\n",
    "sample_inputs = original_tokenizer(sample_text, return_tensors=\"pt\")\n",
    "sample_inputs[\"input_ids\"]\n",
    "sample_result = original_model.forward(sample_inputs[\"input_ids\"])\n",
    "sample_result_label = to_label(np.argmax(sample_result.logits.detach, -1))\n",
    "# print(f'I obtained {sample_inputs}, {np.argmax(sample_result.logits.detach, -1)}')\n",
    "print(f'I obtained {sample_result_label} for {sample_text}')\n",
    "\n",
    "# tokenize the stuff\n",
    "def tokenize(dsin):\n",
    "    return dsin.map(lambda x: original_tokenizer(x[\"text\"], padding=\"max_length\", truncation=True), batched=True)\n",
    "\n",
    "tok_train      = tokenize(part_train)\n",
    "tok_validation = tokenize(part_validation)\n",
    "tok_test       = tokenize(part_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "019b9f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I obtained Bleh! for lovingly photographed in the manner of a golden book sprung to life , stuart little 2 manages sweetness largely without stickiness .\n",
      "I obtained Bleh! for consistently clever and suspenseful .\n",
      "I obtained Bleh! for it's like a \" big chill \" reunion of the baader-meinhof gang , only these guys are more harmless pranksters than political activists .\n",
      "I obtained Bleh! for the story gives ample opportunity for large-scale action and suspense , which director shekhar kapur supplies with tremendous skill .\n",
      "I obtained Bleh! for red dragon \" never cuts corners .\n",
      "I obtained Bleh! for fresnadillo has something serious to say about the ways in which extravagant chance can distort our perspective and throw us off the path of good sense .\n",
      "I obtained Bleh! for throws in enough clever and unexpected twists to make the formula feel fresh .\n",
      "I obtained Bleh! for weighty and ponderous but every bit as filling as the treat of the title .\n",
      "I obtained Bleh! for a real audience-pleaser that will strike a chord with anyone who's ever waited in a doctor's office , emergency room , hospital bed or insurance company office .\n",
      "I obtained Bleh! for generates an enormous feeling of empathy for its characters .\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# standard metric used for classification (I've seen f1 as well...)\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "    return { \"accuracy\": (predictions == labels).mean() } \n",
    "\n",
    "# Alternative, preloading the metric once as library function: Is that faster?\n",
    "metric = eva.load(\"accuracy\")\n",
    "def compute_metrics_2(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# determine how good the untrained original model is, by prompting it for the answers\n",
    "for i in range(10):\n",
    "    review_to_check = part_test[\"text\"][i]\n",
    "    # prompt = 'Do you think the following review is positive? ' + review_to_check # construct a prompt\n",
    "    prompt = review_to_check\n",
    "    tokens = original_tokenizer(prompt, return_tensors=\"pt\")\n",
    "    # print(f'Type of tokens is {type(tokens)} and tokens are {tokens}')\n",
    "    answer = original_model(**tokens)\n",
    "    logits = answer.logits\n",
    "    result_label = to_label(np.argmax(logits.detach, -1))\n",
    "    # print(logits)\n",
    "    print(f'I obtained {result_label} for {review_to_check}')\n",
    "    # probabilities = func.softmax(logits[0], dim=-1)  # argmax?\n",
    "    #print(f'The guess for {review_to_check} is')\n",
    "\n",
    "# That does not yet look meaningful at all! :-("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5176b07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2133' max='2133' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2133/2133 01:10, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.487800</td>\n",
       "      <td>0.425273</td>\n",
       "      <td>0.819887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='267' max='267' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [267/267 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.42527344822883606,\n",
       " 'eval_accuracy': 0.8198874296435272,\n",
       " 'eval_runtime': 7.3364,\n",
       " 'eval_samples_per_second': 145.302,\n",
       " 'eval_steps_per_second': 36.394,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attach a classification head!\n",
    "\n",
    "# Freeze all the parameters of the base model\n",
    "for param in original_model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "original_model.classifier\n",
    "\n",
    "trainer_of_ch = tf.Trainer(\n",
    "    model=original_model,\n",
    "    args=tf.TrainingArguments(\n",
    "        output_dir=\"./data/ch\",\n",
    "        learning_rate=2e-3,\n",
    "        # Reduce the batch size if you don't have enough memory\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        num_train_epochs=1,\n",
    "        weight_decay=0.01,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "    ),\n",
    "    train_dataset = tok_train,\n",
    "    eval_dataset  = tok_validation,\n",
    "    tokenizer     = original_tokenizer,\n",
    "    data_collator = tf.DataCollatorWithPadding(tokenizer=original_tokenizer),\n",
    "    compute_metrics = compute_metrics,\n",
    ")\n",
    "\n",
    "print('===========================================')\n",
    "if TRAIN_CH:\n",
    "    trainer_of_ch.train()\n",
    "print('===========================================')\n",
    "\n",
    "trainer_of_ch.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5775fadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 668,938 || all params: 67,627,028 || trainable%: 0.9891577669212375\n",
      "Now the work starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mbi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\accelerate\\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8532' max='8532' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8532/8532 09:17, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.502400</td>\n",
       "      <td>0.397958</td>\n",
       "      <td>0.829268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.465500</td>\n",
       "      <td>0.602749</td>\n",
       "      <td>0.821764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.372100</td>\n",
       "      <td>0.551544</td>\n",
       "      <td>0.832083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.233000</td>\n",
       "      <td>0.651372</td>\n",
       "      <td>0.833959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a LoRA fine tuning\n",
    "my_target = [\"score\"]\n",
    "if THE_MODEL_I_USE != \"gpt2\":\n",
    "    my_target = [\"classifier\"]\n",
    "\n",
    "# config for \"bert-base-cased\"\n",
    "lora_config = peft.LoraConfig(\n",
    "    task_type=\"SEQ_CLS\",\n",
    "    r=4,           # wild guess, LoRA paper used values between 1 and 16...\n",
    "    lora_alpha=4,  # same as r?\n",
    "    lora_dropout=0.01,\n",
    ")\n",
    "if THE_MODEL_I_USE == \"distilbert-base-uncased\":\n",
    "    lora_config = peft.LoraConfig(\n",
    "        task_type=\"SEQ_CLS\",\n",
    "        r=4,\n",
    "        lora_alpha=4,\n",
    "        lora_dropout=0.01,\n",
    "        # target_modules=[\"q_lin\", \"v_lin\", \"k_lin\", \"out_lin\"],  # this is the theory but stays at 0.5 accuracy\n",
    "        target_modules=[\"q_lin\", \"v_lin\", \"classifier\"],  # this is the theory but stays at 0.5 accuracy\n",
    "        # target_modules=[\"pre_classifier\"],  # throws exception despite also being of type Linear\n",
    "        # target_modules=[\"classifier\"],  # achieves 0.82\n",
    "    )\n",
    "\n",
    "\n",
    "# lora_model = peft.LoraModel(original_model, lora_config, \"default\")\n",
    "lora_model = peft.get_peft_model(original_model, lora_config)\n",
    "lora_model.print_trainable_parameters()\n",
    "\n",
    "# ???\n",
    "\n",
    "original_tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "trainer_for_lora = tf.Trainer(\n",
    "    model = lora_model,\n",
    "    args  = tf.TrainingArguments(\n",
    "        output_dir                  = \"./train/\", # weights saved to some subfolder\n",
    "        learning_rate               = 0.002,\n",
    "        per_device_train_batch_size = 4,\n",
    "        per_device_eval_batch_size  = 4,\n",
    "        evaluation_strategy         = \"epoch\",\n",
    "        save_strategy               = \"epoch\",\n",
    "        num_train_epochs            = 4,     # with GPU 4 epochs take 3 minutes, without... hours! but no improvement after epoch 2\n",
    "        weight_decay                = 0.01,\n",
    "        load_best_model_at_end      = True,\n",
    "    ),\n",
    "    train_dataset   = tok_train,\n",
    "    eval_dataset    = tok_validation,\n",
    "    tokenizer       = original_tokenizer,\n",
    "    data_collator   = tf.DataCollatorWithPadding(tokenizer=original_tokenizer),\n",
    "    compute_metrics = compute_metrics_2,\n",
    ")\n",
    "\n",
    "print(\"Now the work starts\")\n",
    "trainer_for_lora.train()\n",
    "trainer_for_lora.evaluate()\n",
    "lora_model.save_pretrained(NAME_OF_FINETUNED_MODEL)  # use current directory as required in rubric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894046c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d4c908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47abf88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7fe003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "863ec66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForSequenceClassification(\n",
      "  (base_model): LoraModel(\n",
      "    (model): DistilBertForSequenceClassification(\n",
      "      (distilbert): DistilBertModel(\n",
      "        (embeddings): Embeddings(\n",
      "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "          (position_embeddings): Embedding(512, 768)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (transformer): Transformer(\n",
      "          (layer): ModuleList(\n",
      "            (0-5): 6 x TransformerBlock(\n",
      "              (attention): MultiHeadSelfAttention(\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (q_lin): lora.Linear(\n",
      "                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (lora_dropout): ModuleDict(\n",
      "                    (default): Dropout(p=0.01, inplace=False)\n",
      "                  )\n",
      "                  (lora_A): ModuleDict(\n",
      "                    (default): Linear(in_features=768, out_features=4, bias=False)\n",
      "                  )\n",
      "                  (lora_B): ModuleDict(\n",
      "                    (default): Linear(in_features=4, out_features=768, bias=False)\n",
      "                  )\n",
      "                  (lora_embedding_A): ParameterDict()\n",
      "                  (lora_embedding_B): ParameterDict()\n",
      "                )\n",
      "                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (v_lin): lora.Linear(\n",
      "                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (lora_dropout): ModuleDict(\n",
      "                    (default): Dropout(p=0.01, inplace=False)\n",
      "                  )\n",
      "                  (lora_A): ModuleDict(\n",
      "                    (default): Linear(in_features=768, out_features=4, bias=False)\n",
      "                  )\n",
      "                  (lora_B): ModuleDict(\n",
      "                    (default): Linear(in_features=4, out_features=768, bias=False)\n",
      "                  )\n",
      "                  (lora_embedding_A): ParameterDict()\n",
      "                  (lora_embedding_B): ParameterDict()\n",
      "                )\n",
      "                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              )\n",
      "              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (ffn): FFN(\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (activation): GELUActivation()\n",
      "              )\n",
      "              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pre_classifier): ModulesToSaveWrapper(\n",
      "        (original_module): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (modules_to_save): ModuleDict(\n",
      "          (default): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (classifier): ModulesToSaveWrapper(\n",
      "        (original_module): lora.Linear(\n",
      "          (base_layer): Linear(in_features=768, out_features=2, bias=True)\n",
      "          (lora_dropout): ModuleDict(\n",
      "            (default): Dropout(p=0.01, inplace=False)\n",
      "          )\n",
      "          (lora_A): ModuleDict(\n",
      "            (default): Linear(in_features=768, out_features=4, bias=False)\n",
      "          )\n",
      "          (lora_B): ModuleDict(\n",
      "            (default): Linear(in_features=4, out_features=2, bias=False)\n",
      "          )\n",
      "          (lora_embedding_A): ParameterDict()\n",
      "          (lora_embedding_B): ParameterDict()\n",
      "        )\n",
      "        (modules_to_save): ModuleDict(\n",
      "          (default): lora.Linear(\n",
      "            (base_layer): Linear(in_features=768, out_features=2, bias=True)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.01, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=768, out_features=4, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=4, out_features=2, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "lora_reloaded = peft.AutoPeftModelForSequenceClassification.from_pretrained(NAME_OF_FINETUNED_MODEL)\n",
    "print(lora_reloaded)\n",
    "# print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc3a8147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review is lovingly photographed in the manner of a golden book sprung to life , stuart little 2 manages sweetness largely without stickiness .\n",
      "Yay!\n",
      "review is consistently clever and suspenseful .\n",
      "Yay!\n",
      "review is it's like a \" big chill \" reunion of the baader-meinhof gang , only these guys are more harmless pranksters than political activists .\n",
      "Nay!\n",
      "review is the story gives ample opportunity for large-scale action and suspense , which director shekhar kapur supplies with tremendous skill .\n",
      "Yay!\n",
      "review is red dragon \" never cuts corners .\n",
      "Nay!\n",
      "review is fresnadillo has something serious to say about the ways in which extravagant chance can distort our perspective and throw us off the path of good sense .\n",
      "Yay!\n",
      "review is throws in enough clever and unexpected twists to make the formula feel fresh .\n",
      "Yay!\n",
      "review is weighty and ponderous but every bit as filling as the treat of the title .\n",
      "Nay!\n",
      "review is a real audience-pleaser that will strike a chord with anyone who's ever waited in a doctor's office , emergency room , hospital bed or insurance company office .\n",
      "Yay!\n",
      "review is generates an enormous feeling of empathy for its characters .\n",
      "Yay!\n"
     ]
    }
   ],
   "source": [
    "# just for visual checks\n",
    "for i in range(10):\n",
    "    review_to_check = part_test[\"text\"][i]\n",
    "    print(f'review is {review_to_check}')\n",
    "    tokens_of_review = original_tokenizer(review_to_check, return_tensors=\"pt\")\n",
    "    # print(f'tokens are {tokens_of_review.input_ids}')\n",
    "    answer_of_finetuned_model = lora_reloaded(input_ids=tokens_of_review.input_ids)\n",
    "    # print(f'answer is {answer_of_finetuned_model}')\n",
    "    logits = answer_of_finetuned_model.logits\n",
    "    probs = logits[0]\n",
    "    result =  \"Yay!\" if probs[0] < probs[1] else \"Nay!\"\n",
    "    print(result)\n",
    "    # print(type(logits))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc96905a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.43005725741386414, 'test_accuracy': 0.8236397748592871, 'test_runtime': 10.1654, 'test_samples_per_second': 104.866, 'test_steps_per_second': 26.266}\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(tok_test)\n",
    "df = df[[\"text\", \"label\"]]\n",
    "\n",
    "# Add the model predictions to the dataframe\n",
    "# Why is predict part of the trainer?\n",
    "predictions = trainer_for_lora.predict(tok_test)\n",
    "\n",
    "print(predictions.metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866ab28c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a32e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
